{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MRu3aDTNhDF",
    "outputId": "c363d19d-f983-4d6e-8560-86f97ab9b693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JO-Lc3eWYXbK"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "train_data = []\n",
    "with open(\"drive/MyDrive/train.data.jsonl\") as file:\n",
    "    for line in file:\n",
    "        train_data.append(json.loads(line))\n",
    "\n",
    "train_label = json.load(open(\"drive/MyDrive/train.label.json\"))\n",
    "\n",
    "dev_data = []\n",
    "with open(\"drive/MyDrive/dev.data.jsonl\") as file:\n",
    "    for line in file:\n",
    "        dev_data.append(json.loads(line))\n",
    "\n",
    "dev_label = json.load(open(\"drive/MyDrive/dev.label.json\"))\n",
    "\n",
    "test_data = []\n",
    "with open(\"drive/MyDrive/test.data.jsonl\") as file:\n",
    "    for line in file:\n",
    "        test_data.append(json.loads(line))\n",
    "\n",
    "# # \n",
    "# def preprocess_texts(text):\n",
    "#     text = text.lower()\n",
    "#     tt = TweetTokenizer()\n",
    "#     words = tt.tokenize(text)\n",
    "#     new_text = \"\"\n",
    "#     for word in words:\n",
    "#         if word[0] == '@':\n",
    "#             continue\n",
    "#         else:\n",
    "#             new_text += word\n",
    "#             new_text += \" \"\n",
    "#     return new_text[0:-1]\n",
    "\n",
    "import re\n",
    "\n",
    "# regular expression to find english character\n",
    "my_re = re.compile(r'[A-Za-z]')\n",
    "\n",
    "# TODO: \n",
    "def preprocess_texts(text):\n",
    "    text = text.lower()\n",
    "    tt = TweetTokenizer()\n",
    "    words = tt.tokenize(text)\n",
    "    new_text = \"\"\n",
    "    for word in words:\n",
    "        flag = True\n",
    "        for char in word:\n",
    "            if not bool(re.match(my_re, char)):\n",
    "                flag = False\n",
    "        if not flag:\n",
    "            continue\n",
    "        if word[0] == '@':\n",
    "            continue\n",
    "        if word.startswith(\"http\"):\n",
    "            continue\n",
    "        else:\n",
    "            new_text += word\n",
    "            new_text += \" \"\n",
    "    return new_text[0:-1]\n",
    "\n",
    "\n",
    "# \n",
    "def build_input_text():\n",
    "    train_texts = []\n",
    "    dev_texts = []\n",
    "    test_texts = []\n",
    "\n",
    "    train_tweet_to_row = dict()  # tweet id to row\n",
    "    row = 0\n",
    "    for record in train_data:\n",
    "        for tweet in record:\n",
    "            train_texts.append(preprocess_texts(tweet['text']))\n",
    "            train_tweet_to_row[tweet['id_str']] = row\n",
    "            row += 1\n",
    "\n",
    "    dev_tweet_to_row = dict()  # tweet id to row\n",
    "    row = 0\n",
    "    for record in dev_data:\n",
    "        for tweet in record:\n",
    "            dev_texts.append(preprocess_texts(tweet['text']))\n",
    "            dev_tweet_to_row[tweet['id_str']] = row\n",
    "            row += 1\n",
    "\n",
    "    test_tweet_to_row = dict()  # tweet id to row\n",
    "    row = 0\n",
    "    for record in test_data:\n",
    "        for tweet in record:\n",
    "            test_texts.append(preprocess_texts(tweet['text']))\n",
    "            test_tweet_to_row[tweet['id_str']] = row\n",
    "            row += 1\n",
    "    return train_texts, dev_texts, test_texts, train_tweet_to_row, dev_tweet_to_row, test_tweet_to_row\n",
    "\n",
    "\n",
    "train_texts, dev_texts, test_texts, train_tweet_to_row, dev_tweet_to_row, test_tweet_to_row = build_input_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa8khnbWEKnW"
   },
   "outputs": [],
   "source": [
    "# def merge_hashtags(record, data_type):\n",
    "#   tweet_to_row = None\n",
    "#   texts = None\n",
    "#   if data_type == \"train\":\n",
    "#     tweet_to_row = train_tweet_to_row\n",
    "#     texts = train_texts\n",
    "#   elif data_type == \"dev\":\n",
    "#     tweet_to_row = dev_tweet_to_row\n",
    "#     texts = dev_texts\n",
    "#   else:\n",
    "#     tweet_to_row = test_tweet_to_row\n",
    "#     texts = test_texts\n",
    "\n",
    "#   for tweet in record:\n",
    "#     if len(tweet['entities']['hashtags']) > 0:\n",
    "#       texts[tweet_to_row[tweet['id_str']]] += \" \"\n",
    "#       texts[tweet_to_row[tweet['id_str']]] += tweet['entities']['hashtags'][0]['text'].lower()\n",
    "\n",
    "\n",
    "# for record in train_data:\n",
    "#   merge_hashtags(record, \"train\")\n",
    "# for record in dev_data:\n",
    "#   merge_hashtags(record, \"dev\")\n",
    "# for record in test_data:\n",
    "#   merge_hashtags(record, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KlNd5HTYXbU",
    "outputId": "133d5967-ebee-4fa7-a4c6-ec54e1e83dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6000)\n",
      "(1, 6000)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def build_tf_idf_text():\n",
    "    vectorizer = TfidfVectorizer(tokenizer=TweetTokenizer().tokenize,\n",
    "                                 max_df=0.8, min_df=0.00004, max_features=5000, stop_words='english')\n",
    "    train_tf_tdf = vectorizer.fit_transform(train_texts)\n",
    "    dev_tf_tdf = vectorizer.transform(dev_texts)\n",
    "    test_tf_idf = vectorizer.transform(test_texts)\n",
    "    return train_tf_tdf, dev_tf_tdf, test_tf_idf\n",
    "\n",
    "\n",
    "train_tf_tdf, dev_tf_tdf, test_tf_idf = build_tf_idf_text()\n",
    "\n",
    "# TODO: \n",
    "print(train_tf_tdf[0].shape)\n",
    "print(dev_tf_tdf[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ddtxc2kYXbW"
   },
   "outputs": [],
   "source": [
    "# plot the distribution of given values, based on train set\n",
    "def show_value_distribution(param):\n",
    "    values = []\n",
    "    for record in train_data:\n",
    "        values.append(record[0]['user'][param])\n",
    "\n",
    "    plt.hist(values)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# \n",
    "def cut_within_scope(input, scope):\n",
    "    result = np.zeros(len(scope) - 1)\n",
    "    for index, value in enumerate(scope):\n",
    "        if index == len(scope) - 1:\n",
    "            break\n",
    "        if input < scope[index + 1]:\n",
    "            result[index] = 1\n",
    "            break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ygHYcobYXbW"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def get_features(record, data_set_type):\n",
    "    # \n",
    "    source_id = record[0]['id_str']\n",
    "    if data_set_type == 'train':\n",
    "        source_text_vector = train_tf_tdf[train_tweet_to_row[source_id]].toarray()\n",
    "    else:\n",
    "        source_text_vector = dev_tf_tdf[dev_tweet_to_row[source_id]].toarray()\n",
    "    # \n",
    "    source_text_vector = np.squeeze(source_text_vector)\n",
    "\n",
    "    # 2. \n",
    "    reply_text_vectors = []\n",
    "    for reply in record[1:]:\n",
    "        reply_tweet_id = reply['id_str']\n",
    "        if data_set_type == 'train':\n",
    "            reply_text_vectors.append(train_tf_tdf[train_tweet_to_row[reply_tweet_id]].toarray())\n",
    "        else:\n",
    "            reply_text_vectors.append(dev_tf_tdf[dev_tweet_to_row[reply_tweet_id]].toarray())\n",
    "    # \n",
    "    if len(reply_text_vectors) <= 0:\n",
    "        reply_text_vectors = np.zeros(6000)\n",
    "    else:\n",
    "        reply_text_vectors = np.squeeze(np.stack(reply_text_vectors).mean(axis=0))\n",
    "\n",
    "    # verified\n",
    "    verified_vec = [int(record[0]['user']['verified'])]\n",
    "    # friends\n",
    "    friends_vec = cut_within_scope(record[0]['user']['friends_count'],\n",
    "                                   [0, 100, 1000, 5000, 10000, 20000, 50000])\n",
    "    # statuses\n",
    "    statuses_vec = cut_within_scope(record[0]['user']['statuses_count'],\n",
    "                                    [0, 100, 1000, 5000, 10000, 50000, 100000, 200000])\n",
    "    # followers_count\n",
    "    followers_vec = cut_within_scope(record[0]['user']['followers_count'],\n",
    "                                     [0, 1000, 10000, 50000, 100000, 200000, 500000, 1000000, 1500000])\n",
    "    # listed_count\n",
    "    listed_vec = cut_within_scope(record[0]['user']['listed_count'],\n",
    "                                  [0, 10000, 20000, 40000, 100000, 120000, 160000])\n",
    "    # favourites_count\n",
    "    favourites_vec = cut_within_scope(record[0]['user']['favourites_count'],\n",
    "                                      [0, 10000, 20000, 40000, 50000])\n",
    "\n",
    "    return source_text_vector, reply_text_vectors, verified_vec, friends_vec, \\\n",
    "           statuses_vec, followers_vec, listed_vec, favourites_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QgVe3OTYXbX",
    "outputId": "26e00309-114e-459d-cc33-c42cf7c17eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "feature_vector = get_features(train_data[0], data_set_type=\"train\")\n",
    "print(len(feature_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLnnnLRnYXbY"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def get_nb_input_matrix(data_set_type):\n",
    "    data_set = []\n",
    "    labels = []\n",
    "    original_data = None\n",
    "    original_labels = None\n",
    "    if data_set_type == \"train\":\n",
    "        original_data = train_data\n",
    "        original_labels = train_label\n",
    "    else:\n",
    "        original_data = dev_data\n",
    "        original_labels = dev_label\n",
    "\n",
    "    for record in original_data:\n",
    "        source_text_vector, reply_text_vectors, verified_vec, friends_vec, \\\n",
    "        statuses_vec, followers_vec, listed_vec, favourites_vec = get_features(record, data_set_type)\n",
    "\n",
    "        features = np.concatenate([source_text_vector, reply_text_vectors, verified_vec, friends_vec,\n",
    "                                   statuses_vec, followers_vec, listed_vec, favourites_vec])\n",
    "        feature_vector = features\n",
    "        labels.append(original_labels[record[0]['id_str']])\n",
    "        data_set.append(feature_vector)\n",
    "\n",
    "    return np.stack(data_set), labels\n",
    "\n",
    "\n",
    "train_data_matrix, train_label_matrix = get_nb_input_matrix(\"train\")\n",
    "dev_data_matrix, dev_label_matrix = get_nb_input_matrix(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKgAFTvEYXbZ",
    "outputId": "17601ed6-eddc-4462-f5ce-75ff4ce5c9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6037)\n"
     ]
    }
   ],
   "source": [
    "def build_tree_vectors(record, data_set_type):\n",
    "    \"\"\"\n",
    "\n",
    "    :param record:\n",
    "    :param data_set_type:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tf_idf = None\n",
    "    tweet_to_row = None\n",
    "    if data_set_type == \"train\":\n",
    "        tf_idf = train_tf_tdf\n",
    "        tweet_to_row = train_tweet_to_row\n",
    "    elif data_set_type == \"dev\":\n",
    "      tf_idf = dev_tf_tdf\n",
    "      tweet_to_row = dev_tweet_to_row\n",
    "    else:\n",
    "        tf_idf = test_tf_idf\n",
    "        tweet_to_row = test_tweet_to_row\n",
    "\n",
    "    tree_vectors = dict()\n",
    "\n",
    "    for tweet in record:\n",
    "        row = tweet_to_row[tweet[\"id_str\"]]\n",
    "        tf_idf_vec = np.squeeze(tf_idf[row].toarray())\n",
    "\n",
    "        # verified\n",
    "        verified_vec = [int(tweet['user']['verified'])]\n",
    "        # friends\n",
    "        friends_vec = cut_within_scope(tweet['user']['friends_count'],\n",
    "                                       [0, 100, 1000, 5000, 10000, 20000, 50000])\n",
    "        # statuses\n",
    "        statuses_vec = cut_within_scope(tweet['user']['statuses_count'],\n",
    "                                        [0, 100, 1000, 5000, 10000, 50000, 100000, 200000])\n",
    "        # followers_count\n",
    "        followers_vec = cut_within_scope(tweet['user']['followers_count'],\n",
    "                                         [0, 1000, 10000, 50000, 100000, 200000, 500000, 1000000, 1500000])\n",
    "        # listed_count\n",
    "        listed_vec = cut_within_scope(tweet['user']['listed_count'],\n",
    "                                      [0, 10000, 20000, 40000, 100000, 120000, 160000])\n",
    "        # favourites_count\n",
    "        favourites_vec = cut_within_scope(tweet['user']['favourites_count'],\n",
    "                                          [0, 10000, 20000, 40000, 50000])\n",
    "        # protect\n",
    "        retweeted_vec = [int(tweet['user']['protected'])]\n",
    "        # profile_image\n",
    "        profile_image_vec = [int(tweet['user']['default_profile_image'])]\n",
    "        # profile_background\n",
    "        background_vec = [int(tweet['user']['profile_use_background_image'])]\n",
    "        # geo_enabled\n",
    "        geo_vec = [int(tweet['user']['geo_enabled'])]\n",
    "        # profile\n",
    "        profile_vec = [int(tweet['user']['default_profile'])]\n",
    "        \n",
    "        # \n",
    "        feature_vec = np.concatenate([tf_idf_vec, verified_vec, friends_vec,\n",
    "                                   statuses_vec, followers_vec, listed_vec, favourites_vec, retweeted_vec, profile_image_vec, background_vec, geo_vec, \n",
    "                                   profile_vec])\n",
    "        vec = feature_vec.reshape(1, len(feature_vec))\n",
    "        tree_vectors[row] = vec   # \n",
    "        \n",
    "    return tree_vectors\n",
    "\n",
    "print(build_tree_vectors(train_data[0], data_set_type=\"train\")[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfLpocuaYXba"
   },
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tl_aR0AMYXba",
    "outputId": "4d228167-ee05-4691-e4b2-72a4d89d37f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-rumour       0.85      0.91      0.88       393\n",
      "      rumour       0.78      0.66      0.72       187\n",
      "\n",
      "    accuracy                           0.83       580\n",
      "   macro avg       0.82      0.79      0.80       580\n",
      "weighted avg       0.83      0.83      0.83       580\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-rumour       0.87      0.91      0.89      3058\n",
      "      rumour       0.81      0.75      0.78      1583\n",
      "\n",
      "    accuracy                           0.85      4641\n",
      "   macro avg       0.84      0.83      0.83      4641\n",
      "weighted avg       0.85      0.85      0.85      4641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def traditional_model():\n",
    "    \"\"\"\n",
    "\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    from sklearn.naive_bayes import ComplementNB\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    nb = ComplementNB()\n",
    "    nb.fit(train_data_matrix, np.array(train_label_matrix))\n",
    "    print(classification_report(dev_label_matrix, nb.predict(dev_data_matrix)))\n",
    "    print(classification_report(train_label_matrix, nb.predict(train_data_matrix)))\n",
    "    \n",
    "traditional_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHPPMCXDYXba",
    "outputId": "74818083-bc4c-48a7-c641-d95c7f0c3dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pytorch \n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "\n",
    "def topological_order(parent_to_children):\n",
    "    \"\"\"\n",
    "\n",
    "    :param parent_to_children: {0: {1, 3, 4, 5, 6, 7, 8, 11}, 1: {2}, 8: {9, 10}, 2: {12}}\n",
    "    :return: [[12,2],[2,1],[9,10,8],[1, 3, 4, 5, 6, 7, 8, 11, 0]] \n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    queue = [0]  # \n",
    "    while len(queue) > 0:\n",
    "        cur_parent = queue.pop(0)\n",
    "        if cur_parent in parent_to_children:\n",
    "            children = parent_to_children[cur_parent]\n",
    "            result += [list(children) + [cur_parent]]\n",
    "            for child in children:\n",
    "                queue.append(child)\n",
    "    # TODO：\n",
    "    if len(result) <= 0:\n",
    "        result = [[0, 0]]\n",
    "    return list(reversed(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-ogHb5zYXbb"
   },
   "outputs": [],
   "source": [
    "class TreeNN_layer(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, memory_dim):\n",
    "        super(TreeNN_layer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.memory_dim = memory_dim\n",
    "\n",
    "        # \n",
    "        self.E = nn.Linear(input_dim, memory_dim)\n",
    "        self.Wr = nn.Linear(memory_dim, memory_dim)\n",
    "        self.Wz = nn.Linear(memory_dim, memory_dim)\n",
    "        self.Wh = nn.Linear(memory_dim, memory_dim)\n",
    "        self.Ur = nn.Linear(memory_dim, memory_dim)\n",
    "        self.Uz = nn.Linear(memory_dim, memory_dim)\n",
    "        self.Uh = nn.Linear(memory_dim, memory_dim)\n",
    "\n",
    "        # # drop out, \n",
    "        # self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def process(self, vector):\n",
    "        vector = self.E(vector)\n",
    "        # r_j = torch.sigmoid(self.Wr(vector))\n",
    "        z_j = torch.sigmoid(self.Wz(vector))\n",
    "        h_j = torch.tanh(self.Wh(vector))\n",
    "        h_j = z_j * h_j\n",
    "        return h_j\n",
    "\n",
    "    # \n",
    "    def forward(self, parent_vector, children_vectors):\n",
    "        parent_vector_to_memory_shape = self.E(parent_vector)  # 1*memory_dim\n",
    "\n",
    "        h_S = []\n",
    "        for index, vec in enumerate(children_vectors):\n",
    "            # \n",
    "            if vec.size()[1] == self.input_dim:\n",
    "                h_S.append(self.process(vec))\n",
    "            elif vec.size()[1] == self.memory_dim:\n",
    "                h_S.append(vec)\n",
    "\n",
    "        # TODO: \n",
    "        if len(h_S) > 1:\n",
    "            h_S = torch.stack(h_S).squeeze().sum(dim=0)\n",
    "        else:\n",
    "            h_S = h_S[0]\n",
    "\n",
    "        r_j = torch.sigmoid(self.Wr(parent_vector_to_memory_shape) + self.Ur(h_S))\n",
    "        z_j = torch.sigmoid(self.Wz(parent_vector_to_memory_shape) + self.Uz(h_S))\n",
    "        h_j = torch.tanh(self.Wh(parent_vector_to_memory_shape) + self.Uh(h_S * r_j))\n",
    "        h_j = (1 - z_j) * h_S + z_j * h_j\n",
    "        # # TODO：\n",
    "        # h_j = self.dropout(h_j)\n",
    "        return h_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmiS8JirYXbb"
   },
   "outputs": [],
   "source": [
    "class TreeNN(nn.Module):\n",
    "    def __init__(self, input_dim, memory_dim):\n",
    "        super(TreeNN, self).__init__()\n",
    "        self.tree_layer = TreeNN_layer(input_dim, memory_dim)\n",
    "        self.output = nn.Linear(memory_dim, 2)  # \n",
    "\n",
    "    # \n",
    "    def forward(self, orders, index_to_vec):\n",
    "        \"\"\"\n",
    "\n",
    "        :param order: \n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        processed_vecs = dict()\n",
    "        for order in orders:\n",
    "            parent = order[-1]\n",
    "            children = order[:-1]\n",
    "            children_vecs = []\n",
    "            for index in children:\n",
    "                if index in processed_vecs:\n",
    "                    children_vecs.append(processed_vecs[index])\n",
    "                else:\n",
    "                    children_vecs.append(index_to_vec[index])\n",
    "            processed_vecs[parent] = self.tree_layer(index_to_vec[parent], children_vecs)\n",
    "\n",
    "        return self.output(processed_vecs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoU4EW_uYXbc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def show_tree(nodes, edges):\n",
    "    import networkx as netx\n",
    "\n",
    "    tree = netx.DiGraph()\n",
    "    tree.add_nodes_from(nodes)\n",
    "    tree.add_edges_from(edges)\n",
    "    netx.draw_networkx(tree)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# \n",
    "def make_tree(record):\n",
    "    # \n",
    "    nodes = set()\n",
    "    edges = []\n",
    "    tweet_to_index = dict()\n",
    "    index_to_tweet = dict()\n",
    "    index_to_tree = {0: 0}  # \n",
    "\n",
    "    # \n",
    "    for index, tweet in enumerate(record):\n",
    "        tweet_to_index[tweet['id_str']] = index\n",
    "        index_to_tweet[index] = tweet['id_str']\n",
    "\n",
    "    parent_to_children = dict()  \n",
    "    child_to_parent = dict()  \n",
    "\n",
    "\n",
    "    for index, tweet in enumerate(record):\n",
    "\n",
    "        if tweet['in_reply_to_status_id_str'] is not None:\n",
    "            parent_id = tweet['in_reply_to_status_id_str']\n",
    "            parent_index = tweet_to_index.get(parent_id, -1) \n",
    "            if parent_index != -1:\n",
    "                child_to_parent[index] = parent_index\n",
    "    \n",
    "                if parent_index not in parent_to_children:\n",
    "                    parent_to_children[parent_index] = set()\n",
    "                parent_to_children[parent_index].add(index)\n",
    "\n",
    "                if parent_index not in index_to_tree:\n",
    "                    tree = len(index_to_tree)\n",
    "                    index_to_tree[index] = tree\n",
    "                    index_to_tree[parent_index] = tree\n",
    "                else:\n",
    "        \n",
    "                    add_tree(parent_index, index_to_tree, parent_to_children)\n",
    "\n",
    "\n",
    "    for index, tree in index_to_tree.items():\n",
    "        if tree == 0:\n",
    "            nodes.add(index)\n",
    "            if index in child_to_parent:\n",
    "                edges.append([index, child_to_parent[index]])\n",
    "\n",
    "    return nodes, edges, parent_to_children, index_to_tweet, tweet_to_index\n",
    "\n",
    "\n",
    "def add_tree(parent_index, index_to_tree, parent_to_children):\n",
    "    tree = index_to_tree[parent_index]\n",
    "\n",
    "    if parent_index in parent_to_children:\n",
    "        for child in parent_to_children[parent_index]:\n",
    "            \n",
    "            if child not in index_to_tree or index_to_tree[child] != tree:\n",
    "                index_to_tree[child] = tree\n",
    "                add_tree(child, index_to_tree, parent_to_children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x206P-rOYXbc"
   },
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eonp0iMPYXbd"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "model = TreeNN(6037, 64)  # \n",
    "\n",
    " # \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# \n",
    "random.shuffle(train_data)\n",
    "\n",
    "# \n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 2], dtype=torch.float32, device='cuda'))\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 2], dtype=torch.float32))\n",
    "\n",
    "# \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.001, alpha=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYP7aejiYXbd"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def one_hot_label():\n",
    "    train_label_hot = dict()\n",
    "    dev_label_hot = dict()\n",
    "\n",
    "    for id in train_label:\n",
    "        if train_label[id] == 'rumour':\n",
    "            train_label_hot[id] = 1\n",
    "        else:\n",
    "            train_label_hot[id] = 0\n",
    "\n",
    "    for id in dev_label:\n",
    "        if dev_label[id] == 'rumour':\n",
    "            dev_label_hot[id] = 1\n",
    "        else:\n",
    "            dev_label_hot[id] = 0\n",
    "\n",
    "    return train_label_hot, dev_label_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zakNcTgNTyJ"
   },
   "outputs": [],
   "source": [
    "def predict(data_type):\n",
    "    model.eval()\n",
    "    prediction_label = []\n",
    "    real_label = []\n",
    "    data_set = None\n",
    "    tweet_to_row = None\n",
    "    tf_tdf = None\n",
    "    label_hot = None\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        data_set = train_data\n",
    "        tweet_to_row = train_tweet_to_row\n",
    "        tf_tdf = train_tf_tdf\n",
    "        label_hot = one_hot_label()[0]\n",
    "    else:\n",
    "        data_set = dev_data\n",
    "        tweet_to_row = dev_tweet_to_row\n",
    "        tf_tdf = dev_tf_tdf\n",
    "        label_hot = one_hot_label()[1]\n",
    "\n",
    "    for record in data_set:\n",
    "        nodes, edges, parent_to_children, index_to_tweet, tweet_to_index = make_tree(record)\n",
    "        index_to_vec = dict()\n",
    "        \n",
    "        if data_type == \"train\":\n",
    "            tree_vecs = build_tree_vectors(record, \"train\")\n",
    "        else:\n",
    "            tree_vecs = build_tree_vectors(record, \"dev\")\n",
    "\n",
    "        for node in nodes:\n",
    "            tweet_id = index_to_tweet[node]\n",
    "            row = tweet_to_row[tweet_id]\n",
    "            # TODO: \n",
    "            vec = tree_vecs[row]\n",
    "            index_to_vec[node] = torch.tensor(vec, dtype=torch.float32, device='cuda')\n",
    "            # index_to_vec[node] = torch.tensor(vec, dtype=torch.float32)\n",
    "\n",
    "        order = topological_order(parent_to_children)\n",
    "        output = model(order, index_to_vec)\n",
    "        predicted_label = output.cpu().argmax().item()\n",
    "        prediction_label.append(predicted_label)\n",
    "\n",
    "        cur_id = record[0]['id_str']\n",
    "        label = label_hot[cur_id]\n",
    "        real_label.append(label)\n",
    "\n",
    "    return prediction_label, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "id": "dUqAldWqYXbe",
    "outputId": "a4887896-940c-4a3c-f68f-739a1f4b0aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----the current rumour f1 of dev_data----\n",
      "0.7142857142857142\n",
      "epoch 1 finished, the average loss is tensor(9.8215e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n",
      "----the current rumour f1 of dev_data----\n",
      "0.7893333333333333\n",
      "epoch 2 finished, the average loss is tensor(7.5936e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n",
      "----the current rumour f1 of dev_data----\n",
      "0.7722772277227723\n",
      "epoch 3 finished, the average loss is tensor(8.2210e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n",
      "----the current rumour f1 of dev_data----\n",
      "0.7635467980295567\n",
      "epoch 4 finished, the average loss is tensor(8.3366e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n",
      "----the current rumour f1 of dev_data----\n",
      "0.7280898876404494\n",
      "epoch 5 finished, the average loss is tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n",
      "----the current rumour f1 of dev_data----\n",
      "0.7155555555555556\n",
      "epoch 6 finished, the average loss is tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-76391b3323ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 带drop out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# torch.save(model.state_dict(), \"drive/MyDrive/model.pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-76391b3323ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, steps, model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_to_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_to_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m# predicted_label = output.cpu().argmax().item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# train_prediction_label.append(predicted_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-396b926716d5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, orders, index_to_vec)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mchildren_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# 把父节点处理后的结果扔进去\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mprocessed_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 最后输出的是处理过的source tweet，映射成二维数组输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-52790898ca0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, parent_vector, children_vectors)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mr_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_vector_to_memory_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mz_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_vector_to_memory_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mh_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_vector_to_memory_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_S\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mh_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mz_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_S\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz_j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# # TODO： 这里改了\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "def train(epochs, steps, model):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    train_prediction_label = []\n",
    "    train_real_label = []\n",
    "\n",
    "    epochs_no_improve = 0\n",
    "    max_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()  # \n",
    "        count = 0  # \n",
    "        for record in train_data:\n",
    "            nodes, edges, parent_to_children, index_to_tweet, tweet_to_index = make_tree(record)\n",
    "            index_to_vec = dict()\n",
    "            tree_vecs = build_tree_vectors(record, \"train\")\n",
    "\n",
    "            for node in nodes:\n",
    "                # TODO: \n",
    "                tweet_id = index_to_tweet[node]\n",
    "                row = train_tweet_to_row[tweet_id]\n",
    "                vec = tree_vecs[row]\n",
    "                index_to_vec[node] = torch.tensor(vec, dtype=torch.float32, device='cuda')\n",
    "                # index_to_vec[node] = torch.tensor(vec, dtype=torch.float32)\n",
    "\n",
    "            order = topological_order(parent_to_children)\n",
    "            output = model(order, index_to_vec)\n",
    "            # predicted_label = output.cpu().argmax().item()\n",
    "            # train_prediction_label.append(predicted_label)\n",
    "\n",
    "            # TODO: \n",
    "            train_label_hot = one_hot_label()[0]\n",
    "            cur_id = record[0]['id_str']\n",
    "            label = train_label_hot[cur_id]\n",
    "            # train_real_label.append(label)\n",
    "            label_tensor = torch.tensor([label], dtype=torch.long, device='cuda')\n",
    "            # label_tensor = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "            loss = criterion(output, label_tensor)\n",
    "            loss.backward()\n",
    "            count += 1\n",
    "\n",
    "            # \n",
    "            if count % steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()  # \n",
    "\n",
    "        # TODO: \n",
    "        # random.shuffle(dev_data)\n",
    "        real_label = predict(\"dev\")[1]\n",
    "        predicted_label = predict(\"dev\")[0]\n",
    "        dev_f1 = f1_score(real_label, predicted_label)\n",
    "        print(\"----the current rumour f1 of dev_data----\")\n",
    "        print(dev_f1)\n",
    "\n",
    "        print(\"epoch \" + str(epoch + 1) + \" finished, the average loss is \" + str(loss / len(train_data)))\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        model.train()  # \n",
    "\n",
    "        # \n",
    "        if dev_f1 > max_f1:\n",
    "          # best_model_state = model.state_dict()\n",
    "          torch.save(model.state_dict(),\"drive/MyDrive/best.pth\")\n",
    "          max_f1 = dev_f1\n",
    "          epochs_no_improve = 0\n",
    "        else:\n",
    "          epochs_no_improve += 1\n",
    "\n",
    "        if epoch >= 10 and epochs_no_improve >= 6:\n",
    "          print(\"no improve, stop training!!\")\n",
    "          break\n",
    "        \n",
    "\n",
    "    # return best_model_state\n",
    "\n",
    "\n",
    "model.train()  #\n",
    "train(100, 64, model)\n",
    "model.load_state_dict(torch.load('drive/MyDrive/best.pth'))\n",
    "# torch.save(model.state_dict(), \"drive/MyDrive/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BvWQ2kzYXbe"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('drive/MyDrive/best.pth'))\n",
    "train_prediction_label, train_real_label = predict(\"train\")\n",
    "dev_prediction_label, dev_real_label = predict(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXRt8AwXYXbf",
    "outputId": "47ea6d69-3a0d-4683-dd3f-444432dfda9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----the result of train_data----\n",
      "accuracy: 0.9103641456582633\n",
      "rumour: f1 is 0.870404984423676, recall is 0.8825015792798484, precision is 0.8586355255070682\n",
      "non_rumour: f1 is 0.9314888010540184, recall is 0.9247874427730542, precision is 0.9382879893828799\n",
      "----the result of dev_data----\n",
      "accuracy: 0.8637931034482759\n",
      "rumour: f1 is 0.7893333333333333, recall is 0.7914438502673797, precision is 0.7872340425531915\n",
      "non_rumour: f1 is 0.8993630573248408, recall is 0.8982188295165394, precision is 0.9005102040816326\n"
     ]
    }
   ],
   "source": [
    "def show_result(data_set):\n",
    "    real = None\n",
    "    prediction = None\n",
    "    if data_set == \"train\":\n",
    "        real = train_real_label\n",
    "        prediction = train_prediction_label\n",
    "    else:\n",
    "        real = dev_real_label\n",
    "        prediction = dev_prediction_label\n",
    "\n",
    "    acc = accuracy_score(real, prediction)\n",
    "    rumor_f1 = f1_score(real, prediction)\n",
    "    non_rumor_f1 = f1_score(real, prediction, pos_label=0)\n",
    "    rumor_precision = precision_score(real, prediction)\n",
    "    non_rumor_precision = precision_score(real, prediction, pos_label=0)\n",
    "    rumor_recall = recall_score(real, prediction)\n",
    "    non_rumor_recall = recall_score(real, prediction, pos_label=0)\n",
    "\n",
    "    if data_set == \"train\":\n",
    "        print(\"----the result of train_data----\")\n",
    "    else:\n",
    "        print(\"----the result of dev_data----\")\n",
    "\n",
    "    print(\"accuracy: \" + str(acc))\n",
    "    print(\"rumour: f1 is \" + str(rumor_f1) + \", recall is \" + str(rumor_recall) + \", precision is \" +\n",
    "          str(rumor_precision))\n",
    "    print(\"non_rumour: f1 is \" + str(non_rumor_f1) + \", recall is \" + str(non_rumor_recall) + \", precision is \" +\n",
    "          str(non_rumor_precision))\n",
    "\n",
    "show_result(\"train\")\n",
    "show_result(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "464mgk5XtMC2",
    "outputId": "07314fa7-b7d0-4db3-8789-7247de10d347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'544382249178001408': 'rumour', '525027317551079424': 'rumour', '544273220128739329': 'rumour', '499571799764770816': 'non-rumour', '552844104418091008': 'non-rumour', '524977651476623360': 'rumour', '544514988078280704': 'non-rumour', '524928863714168832': 'rumour', '544390718253699072': 'non-rumour', '580322349569994752': 'rumour', '544475905926524928': 'non-rumour', '544389986809036800': 'non-rumour', '498530293116968960': 'non-rumour', '498293625420148736': 'non-rumour', '552831230735962113': 'non-rumour', '553589469849583616': 'rumour', '544415816851021824': 'non-rumour', '552850116324130816': 'non-rumour', '544318036715782144': 'non-rumour', '524974318087061504': 'rumour', '553592195786506240': 'rumour', '524959778125385728': 'non-rumour', '553502311872733184': 'non-rumour', '499698366402789376': 'non-rumour', '525032872647065600': 'rumour', '553110609513177088': 'non-rumour', '544267656597995521': 'rumour', '552845393541988352': 'non-rumour', '500422971320963072': 'non-rumour', '553197197618339841': 'non-rumour', '500351760402493440': 'non-rumour', '553147341470203906': 'non-rumour', '524939821815721984': 'non-rumour', '544376469279875072': 'non-rumour', '544438309267578880': 'non-rumour', '544453205682556928': 'non-rumour', '552821573946982401': 'non-rumour', '552817675408523264': 'non-rumour', '544336432609775618': 'non-rumour', '552825473160736768': 'non-rumour', '544429350376861696': 'non-rumour', '552846544320618496': 'non-rumour', '524950203476869120': 'non-rumour', '500371231183745025': 'rumour', '500234390723915776': 'non-rumour', '544515971637968898': 'non-rumour', '544382795099799553': 'non-rumour', '553194557316542465': 'non-rumour', '552837644959621120': 'non-rumour', '553535829529100288': 'rumour', '544465862942797825': 'non-rumour', '581183387848859648': 'non-rumour', '544487579048222721': 'non-rumour', '499531968229683200': 'non-rumour', '498294764718915586': 'rumour', '500298315368390657': 'rumour', '544513510450155520': 'non-rumour', '580329219646988289': 'rumour', '500382853147164672': 'non-rumour', '544353502689251329': 'rumour', '552814137857036289': 'non-rumour', '524956415589621760': 'non-rumour', '553485654030446592': 'non-rumour', '552840606074953728': 'non-rumour', '552833527444566016': 'non-rumour', '499541439962185729': 'non-rumour', '552824885484224513': 'non-rumour', '499586890837016579': 'non-rumour', '552821810572439553': 'rumour', '544310222547087361': 'non-rumour', '552790565642067968': 'non-rumour', '553103772852191233': 'non-rumour', '500072455931588611': 'non-rumour', '580323877429112832': 'non-rumour', '524969501704855552': 'rumour', '524979702940045313': 'non-rumour', '499427218171248641': 'rumour', '524958409381384192': 'non-rumour', '552848590373392384': 'non-rumour', '524967510563889152': 'non-rumour', '580333904126742528': 'rumour', '544293021995393024': 'non-rumour', '553502446769942528': 'non-rumour', '544326461952241664': 'rumour', '553226143307161600': 'non-rumour', '524936793633083394': 'non-rumour', '552848704819183616': 'non-rumour', '499691593985957888': 'non-rumour', '499432169836531712': 'non-rumour', '580347360959717376': 'rumour', '544426421331169280': 'non-rumour', '553227441712668672': 'non-rumour', '544388658334146561': 'rumour', '552831761957523456': 'non-rumour', '544374018661687296': 'rumour', '500297243371798528': 'non-rumour', '553208762291339265': 'non-rumour', '500320286341099523': 'non-rumour', '552784526955806720': 'rumour', '552978099357237248': 'rumour', '500284494201757696': 'rumour', '525021083892994049': 'rumour', '499637476315910146': 'non-rumour', '524962199543230464': 'rumour', '499606771246567424': 'non-rumour', '552833795142209536': 'non-rumour', '552824126659104771': 'non-rumour', '544278985249550337': 'non-rumour', '553475269873643520': 'non-rumour', '525032458417610752': 'non-rumour', '499357077429817344': 'non-rumour', '498497371899449344': 'rumour', '525023858831523841': 'rumour', '544285245600989184': 'rumour', '500364250461003777': 'rumour', '553491517462315008': 'non-rumour', '552837499937378305': 'non-rumour', '553215658784456705': 'non-rumour', '553145236268916736': 'non-rumour', '499596695705894912': 'non-rumour', '544466920880492544': 'rumour', '500277382461530112': 'rumour', '553216874130206721': 'non-rumour', '552810032765497345': 'non-rumour', '544313370892324864': 'non-rumour', '500422447623966721': 'non-rumour', '544341194822520832': 'rumour', '552806056154644480': 'rumour', '500300813835988992': 'non-rumour', '544462918465503233': 'non-rumour', '552996335319007233': 'non-rumour', '500377192841609217': 'non-rumour', '553536603998945280': 'rumour', '544284455909998592': 'rumour', '524978196589334529': 'non-rumour', '544427938372792321': 'rumour', '552799640488517632': 'rumour', '552826150141960192': 'non-rumour', '500296369224310784': 'non-rumour', '553124783043649537': 'non-rumour', '499464258183114754': 'non-rumour', '553588704913416192': 'non-rumour', '581317224096387072': 'rumour', '580364973664309248': 'rumour', '499692788993511424': 'non-rumour', '544478625383608320': 'non-rumour', '553472225798795264': 'rumour', '553591049541914624': 'non-rumour', '524943012602716160': 'non-rumour', '544282355989753857': 'rumour', '525020733622464512': 'rumour', '553157857215262721': 'non-rumour', '544410050572582912': 'rumour', '544329393737170944': 'non-rumour', '525026715123601408': 'rumour', '552834732325879809': 'non-rumour', '552822314157768704': 'non-rumour', '552804839886184448': 'rumour', '544274544174071809': 'rumour', '553576010898497536': 'rumour', '544410900854091776': 'non-rumour', '580326762673901568': 'rumour', '552803792618799106': 'non-rumour', '552823427862908928': 'non-rumour', '553506985413713920': 'non-rumour', '500311883669585920': 'non-rumour', '544351885298130945': 'rumour', '544469609433563136': 'non-rumour', '500307001629745152': 'rumour', '524927288077746176': 'rumour', '552825211654246401': 'non-rumour', '544319905076903936': 'non-rumour', '524964630221705216': 'non-rumour', '553218599390040065': 'non-rumour', '544391412075069440': 'non-rumour', '499364002318020608': 'non-rumour', '500343812863311872': 'rumour', '553511279235964928': 'non-rumour', '552847959864274944': 'non-rumour', '553165824979386368': 'non-rumour', '499437429690888192': 'non-rumour', '500413012822745090': 'rumour', '580377478184755201': 'rumour', '500315536937324544': 'non-rumour', '525038096086499328': 'rumour', '580364656608428032': 'rumour', '580321156508577792': 'rumour', '524961055211286528': 'non-rumour', '580354367796166656': 'non-rumour', '544427255439425536': 'non-rumour', '553175336926449664': 'non-rumour', '553099479381848064': 'non-rumour', '524958498770395137': 'rumour', '544519635916169218': 'rumour', '499440386767859712': 'non-rumour', '553542282100871168': 'rumour', '553584782987497474': 'non-rumour', '552815122897727488': 'non-rumour', '553099050409807872': 'non-rumour', '553167429665587200': 'rumour', '525050193360613376': 'non-rumour', '500234112054341632': 'rumour', '500332042648055808': 'rumour', '500313811195158528': 'non-rumour', '553556643456507904': 'rumour', '553192366098898945': 'non-rumour', '524962748237889536': 'rumour', '524959090125320193': 'non-rumour', '498300256678076417': 'non-rumour', '553512076304728064': 'non-rumour', '544414686935285760': 'non-rumour', '500287538578587648': 'non-rumour', '498276354434277376': 'non-rumour', '524949073154301952': 'rumour', '525021050627973120': 'non-rumour', '524977830124617728': 'non-rumour', '544401106617786370': 'rumour', '552824705703763969': 'non-rumour', '524944006577668096': 'rumour', '581153923987206146': 'rumour', '500359125310922753': 'rumour', '544512078518968320': 'non-rumour', '553535765997969408': 'non-rumour', '580364138020507649': 'rumour', '553491005971132416': 'non-rumour', '553205115830951936': 'non-rumour', '552844643097120768': 'non-rumour', '544416937178976256': 'non-rumour', '500371149713178625': 'non-rumour', '500278978557804544': 'non-rumour', '553539631149756416': 'non-rumour', '552841049467400192': 'non-rumour', '553474514496278528': 'rumour', '553536887349325825': 'rumour', '552835339325558785': 'non-rumour', '544328894812549121': 'rumour', '553583867664535552': 'non-rumour', '544328059482939392': 'non-rumour', '524965242213007360': 'non-rumour', '524930671220105216': 'rumour', '544379366474403840': 'rumour', '553528503573184514': 'non-rumour', '524942952733220865': 'rumour', '499360762167848960': 'non-rumour', '544362279006113792': 'rumour', '499611069565112320': 'non-rumour', '553546292748898304': 'non-rumour', '553588106587545600': 'rumour', '499706791396392960': 'non-rumour', '553534934447824896': 'non-rumour', '544277516773380097': 'rumour', '500407038800056321': 'rumour', '552795953301045248': 'non-rumour', '552828400843620353': 'non-rumour', '498272364560257025': 'non-rumour', '544285712653500419': 'rumour', '553107688591089664': 'non-rumour', '552813160110252032': 'non-rumour', '499659628645720064': 'non-rumour', '544390550497947649': 'non-rumour', '524971492820647936': 'rumour', '580326222107951104': 'non-rumour', '553185404657352704': 'non-rumour', '553129811850559488': 'non-rumour', '544309177859203073': 'rumour', '524950455743291392': 'non-rumour', '524955388190662657': 'rumour', '500367267901632512': 'non-rumour', '500363126294863876': 'rumour', '552788555584765952': 'non-rumour', '553143519536500738': 'rumour', '552807328287064065': 'non-rumour', '498341675476217856': 'non-rumour', '552825257707335680': 'non-rumour', '524935633463037953': 'rumour', '544341406094213121': 'non-rumour', '544435176479027200': 'non-rumour', '552824320389435392': 'rumour', '580320745974288384': 'rumour', '498251940997136384': 'non-rumour', '553582206019723264': 'non-rumour', '553589372084162560': 'rumour', '580332189155459072': 'rumour', '544268637134393344': 'rumour', '544338731210399744': 'rumour', '553226059836297216': 'non-rumour', '553529796601585664': 'rumour', '524974975623892992': 'non-rumour', '553222727700865025': 'non-rumour', '499435341259223040': 'non-rumour', '553478677359775744': 'rumour', '498356729634390016': 'non-rumour', '553531783992868864': 'rumour', '499691638424608768': 'non-rumour', '552826580741795840': 'non-rumour', '544434192478519297': 'non-rumour', '553548404102414337': 'non-rumour', '524943886553468929': 'rumour', '580322026029654018': 'non-rumour', '499438052688023552': 'non-rumour', '499394946416529409': 'non-rumour', '499583349267382273': 'non-rumour', '524961721744900097': 'rumour', '581293685041557504': 'rumour', '553589657695715328': 'non-rumour', '524955083297931264': 'non-rumour', '552981833189969921': 'rumour', '553174338380517376': 'non-rumour', '552830966411321344': 'non-rumour', '553549680538578944': 'non-rumour', '524952094986350592': 'rumour', '500359356589019136': 'rumour', '498489114384420865': 'rumour', '552818988468944897': 'non-rumour', '544361776020586496': 'rumour', '553233130275221504': 'non-rumour', '580882417117958144': 'rumour', '544453251068743681': 'non-rumour', '499376069485821952': 'non-rumour', '524947036228317184': 'non-rumour', '525039002307424256': 'rumour', '499696137708658688': 'non-rumour', '544408991649251329': 'non-rumour', '553176929411825664': 'non-rumour', '544494652418949120': 'non-rumour', '524979881525137409': 'non-rumour', '553503546382249984': 'non-rumour', '553582801833185280': 'non-rumour', '553550030553243650': 'non-rumour', '524964457936863232': 'non-rumour', '580335545265627136': 'rumour', '500329800725442562': 'non-rumour', '553153190859141120': 'non-rumour', '544520042810200064': 'rumour', '499556227874304000': 'non-rumour', '552831978522021890': 'non-rumour', '553587329626292224': 'non-rumour', '544300674448887809': 'non-rumour', '552981008518500353': 'non-rumour', '580322927679279105': 'rumour', '544269749405097984': 'rumour', '500295333486657536': 'rumour', '499349294034743297': 'non-rumour', '553587352086384640': 'non-rumour', '544516478821613569': 'rumour', '544500883963518976': 'non-rumour', '544518803225604096': 'rumour', '524941504796962816': 'rumour', '552832584045330432': 'non-rumour', '500298847550472194': 'rumour', '544494058287423489': 'non-rumour', '525070811439579138': 'non-rumour', '544519140552507392': 'rumour', '525001708318240768': 'non-rumour', '552982124274647042': 'non-rumour', '544291966536523776': 'non-rumour', '544414430025371649': 'rumour', '500364914796802048': 'non-rumour', '544301961638457344': 'non-rumour', '500385585807499266': 'non-rumour', '499394221984714752': 'non-rumour', '580319651399385088': 'rumour', '544432661419155456': 'non-rumour', '580324721381740544': 'rumour', '544318880001560576': 'rumour', '553567184002502656': 'non-rumour', '553580499395174400': 'non-rumour', '500388703114895360': 'rumour', '498294367405477888': 'non-rumour', '525000220371734528': 'non-rumour', '553540824768991233': 'non-rumour', '580320995266936832': 'rumour', '553153740925304832': 'non-rumour', '498267196833808384': 'non-rumour', '544391790615605249': 'non-rumour', '552985855854661633': 'rumour', '552806890498191361': 'non-rumour', '552808242276229120': 'non-rumour', '524931830173421568': 'rumour', '524979179235069952': 'non-rumour', '500360632093646848': 'non-rumour', '500070699768496128': 'non-rumour', '544466903364673536': 'non-rumour', '500369097360953345': 'non-rumour', '500072334578159616': 'non-rumour', '525053517531062272': 'non-rumour', '553149163181838336': 'non-rumour', '544353552177455104': 'rumour', '544510827433558016': 'rumour', '499643185581142016': 'non-rumour', '552828658747187201': 'non-rumour', '544397240601563137': 'non-rumour', '524951585231994880': 'rumour', '499703651079045121': 'non-rumour', '544352727971954690': 'rumour', '552843136238899200': 'non-rumour', '580320242020290560': 'rumour', '500274697485824000': 'non-rumour', '500364003734867970': 'non-rumour', '552821030117711872': 'non-rumour', '580334563932549120': 'rumour', '553555848794877952': 'non-rumour', '500266967102914560': 'non-rumour', '552837027616804864': 'non-rumour', '500309381930844160': 'non-rumour', '500359983301939200': 'rumour', '544492984880754688': 'rumour', '499409455814287360': 'non-rumour', '499642374428307457': 'non-rumour', '524933380929245184': 'rumour', '553187959835725824': 'non-rumour', '552816883012239360': 'non-rumour', '499667557247614977': 'non-rumour', '524941124893700096': 'rumour', '544292129972170752': 'rumour', '544495359800930304': 'rumour', '552844436460560384': 'non-rumour', '499706705354448897': 'non-rumour', '499365436816105473': 'non-rumour', '552978586559188992': 'non-rumour', '544369574842347520': 'non-rumour', '553192641328734208': 'non-rumour', '524947149134774272': 'rumour', '552794995942772736': 'non-rumour', '553587511864598529': 'non-rumour', '552815443959091200': 'non-rumour', '580347361039413248': 'rumour', '524957974226550784': 'non-rumour', '544487291465392128': 'non-rumour', '524965775036387329': 'rumour', '500296080710705152': 'non-rumour', '553159773555023872': 'non-rumour', '553487579077550082': 'non-rumour', '498294775649665024': 'non-rumour', '524944610985263104': 'non-rumour', '553555389611274240': 'rumour', '544289941996326912': 'non-rumour', '524955243185176576': 'non-rumour', '544403765575839744': 'non-rumour', '544336537870434304': 'rumour', '524978999534317568': 'non-rumour', '544315472075042818': 'rumour', '500315532382707712': 'non-rumour', '525027651908800512': 'rumour', '544446828654366720': 'rumour', '552851772658561028': 'non-rumour', '524928195011698688': 'non-rumour', '553589285342175232': 'rumour', '544335202923737089': 'non-rumour', '552815293349650433': 'non-rumour', '553581958455123968': 'non-rumour', '525012689568161792': 'non-rumour', '553121732387946496': 'non-rumour', '552812623658762240': 'non-rumour', '544437798426509312': 'non-rumour', '553484760233017344': 'rumour', '553554585634496512': 'rumour', '552846565950627840': 'non-rumour', '525025329916948481': 'rumour', '553148339160907776': 'rumour', '499655603405725696': 'non-rumour', '500316260081889282': 'non-rumour', '553139058827096064': 'non-rumour', '553152208691539968': 'non-rumour', '525034332474601472': 'non-rumour', '498349598197702656': 'rumour', '525047104239333377': 'rumour', '553110339236409346': 'rumour', '552814410763603968': 'non-rumour', '552792253601947648': 'non-rumour', '552814770542628865': 'non-rumour', '580330362070540288': 'non-rumour', '580340423044018176': 'non-rumour', '500385877684539393': 'non-rumour', '499665704300191745': 'non-rumour', '499651830951841794': 'non-rumour', '544369653015801856': 'non-rumour', '581307361857392642': 'rumour', '499601956491374594': 'non-rumour', '524924034124107776': 'rumour', '580327960638521344': 'non-rumour', '525002243100401664': 'rumour', '525028171549523971': 'rumour', '499530130487017472': 'non-rumour', '498271531386953728': 'non-rumour', '580337440738713600': 'non-rumour', '544477048048082945': 'non-rumour', '524938162900967424': 'rumour', '524983366261936130': 'rumour', '544387669766451200': 'rumour', '524945676443340800': 'rumour', '580350403734310912': 'non-rumour', '553531343834202112': 'rumour', '500277477986828288': 'rumour', '552807101442322432': 'non-rumour', '499705915227271168': 'non-rumour', '544299439087550464': 'rumour', '553589860880375808': 'non-rumour', '524983146266505216': 'rumour', '552805175874686977': 'non-rumour', '553464709899616257': 'non-rumour', '553144712920834048': 'non-rumour', '500364921607974913': 'non-rumour', '525052223030845440': 'rumour', '544499449645768706': 'non-rumour', '500396427378298880': 'non-rumour', '544309283048144897': 'non-rumour', '500378522788315137': 'rumour', '500366417674268673': 'non-rumour', '553214358948683776': 'non-rumour', '552806937470201856': 'non-rumour', '553231516290269184': 'non-rumour', '499581876668227584': 'rumour', '544518337498058753': 'non-rumour', '552805069956329472': 'non-rumour', '524937330923417600': 'rumour', '525038296921960449': 'non-rumour', '553466230989144064': 'rumour', '544419162001383424': 'non-rumour', '524966596897685504': 'non-rumour', '580328708675887104': 'rumour', '524969878823137280': 'rumour', '553548567420628992': 'rumour', '524935769614331904': 'rumour', '499592320900431872': 'non-rumour', '544274934835707905': 'rumour', '552790598823186432': 'non-rumour', '553590835850514433': 'rumour', '552811438994378754': 'non-rumour', '544272134764122112': 'rumour', '552791332935434242': 'non-rumour', '499703127193305088': 'non-rumour', '553588494661337089': 'rumour', '499660656769921025': 'non-rumour', '553118384540643328': 'non-rumour', '500288349924782080': 'rumour', '544296985910861824': 'rumour', '544487535418687488': 'rumour', '544409400941625344': 'non-rumour', '553203041705664513': 'non-rumour', '499658267493019651': 'non-rumour', '499397804620386304': 'non-rumour', '524935246647926784': 'rumour', '553172769819852800': 'non-rumour', '498300128088694786': 'non-rumour', '544516940367413248': 'rumour', '525034457086959616': 'non-rumour', '524935085863481344': 'rumour', '553519997956669440': 'non-rumour', '580336069192843264': 'non-rumour', '553553331671408641': 'rumour', '544380899639689216': 'non-rumour', '524944788525973505': 'non-rumour', '581247335998431232': 'non-rumour', '544470398881259520': 'non-rumour', '580325043705667586': 'rumour', '500316380063748096': 'non-rumour', '525067386849091584': 'non-rumour', '580346858846822400': 'non-rumour', '553589606307090432': 'rumour', '553581669710831617': 'non-rumour', '525006356731166720': 'rumour', '553124268196642816': 'non-rumour', '552839416620658688': 'rumour', '553552825431883776': 'rumour', '553229948153262081': 'non-rumour', '544518415952539649': 'rumour', '544384394337611776': 'rumour', '524973811092193280': 'rumour', '544323450270392322': 'non-rumour', '544426670095368192': 'non-rumour', '553171877464920064': 'non-rumour', '552843285468020736': 'non-rumour', '553541988490825728': 'rumour', '553561169923829760': 'non-rumour', '525035552643751936': 'rumour', '553581227165642752': 'non-rumour', '552816302780579840': 'non-rumour', '580350000074457088': 'non-rumour', '498584409055174656': 'non-rumour', '524961070465945600': 'non-rumour'}\n",
      "加载入文件完成...\n"
     ]
    }
   ],
   "source": [
    "def get_test_result():\n",
    "    test_prediction_label = {}\n",
    "\n",
    "    for record in test_data:\n",
    "        nodes, edges, parent_to_children, index_to_tweet, tweet_to_index = make_tree(record)\n",
    "        index_to_vec = dict()\n",
    "        tree_vecs = build_tree_vectors(record, \"test\")\n",
    "\n",
    "        for node in nodes:\n",
    "            tweet_id = index_to_tweet[node]\n",
    "            row = test_tweet_to_row[tweet_id]\n",
    "            vec = tree_vecs[row]\n",
    "            index_to_vec[node] = torch.tensor(vec, dtype=torch.float32, device='cuda')\n",
    "            # index_to_vec[node] = torch.tensor(vec, dtype=torch.float32)\n",
    "\n",
    "        order = topological_order(parent_to_children)\n",
    "        output = model(order, index_to_vec)\n",
    "        predicted_label = output.cpu().argmax().item()\n",
    "        if predicted_label == 0:\n",
    "          predicted_label = \"non-rumour\"\n",
    "        else:\n",
    "          predicted_label = \"rumour\"\n",
    "        source_id = record[0]['id_str']\n",
    "        test_prediction_label[source_id] = predicted_label\n",
    "\n",
    "    return test_prediction_label\n",
    "\n",
    "result_dic = get_test_result()\n",
    "print(result_dic)\n",
    "with open(\"drive/MyDrive/test-output.json\",\"w\") as f:\n",
    "  json.dump(result_dic,f)\n",
    "  print(\"加载入文件完成...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1Pwt4tLYXbf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "nlp_proj_过拟合解决.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
